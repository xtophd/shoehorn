## Authors: 
##   Christoph Doerbeck
##
## Summary:
##


- delegate_to: localhost
  block:

    ##
    ##    NOTE: All tasks here are blocked and delegated to excute
    ##          on the deployhost/localhost 
    ##


    ##
    ##    Log in to the oVIRT API service
    ##
    ##    NOTE: username and password should be in
    ##          the encrypted credentials.yml file
    ##
    ##    NOTE: to avoid concurrency problems with
    ##          hitting the api at scale, we
    ##          set 'throttle = 1'
    ##
    
    
    
    - name: "ovirt-deploy : Login to oVirt"
      throttle: 1
      ovirt_auth:
        hostname: "{{ xtoph_deploy.ovirt.api.fqdn }}"
        ca_file:  "{{ xtoph_deploy.ovirt.engine_cafile | default(omit) }}"
        insecure: "{{ xtoph_deploy.ovirt.insecure |  default(true) }}"
        username: "{{ ovirt_username }}"
        password: "{{ ovirt_password }}"
        state:    present



    ##
    ##    Determine state of the vm
    ##
    
    
    
    - name: "ovirt-deploy : determine state of vm"
      ovirt_vm_info:
        pattern: name="{{ xtoph_deploy.ovirt.vm.name }}" cluster="{{ xtoph_deploy.ovirt.cluster_name }}"
        auth: "{{ ovirt_auth }}"
      register: vminfo_result
      ignore_errors: true
    
    

    - name: "ovirt-deploy : DEBUG vm status/info results"
      debug: var=vminfo_result
      when: xtoph_deploy.debug == true
    
    
    
    ##
    ##    If the node is absent OR node NOT up, 
    ##    then set_fact to deploy the node
    ##
    
    
    
    - set_fact:
        deploy_node: false
    
    - set_fact:
        deploy_node: true
      when: vminfo_result.ovirt_vms|length == 0
    
    - set_fact:
        deploy_node: true
      when:
        - vminfo_result.ovirt_vms[0].status is defined
        - vminfo_result.ovirt_vms[0].status != "up"
    
    - name:  "ovirt-deploy : DEBUG vm status/info results"
      debug:
        msg: "deploy_node = {{ deploy_node }}"
      when: xtoph_deploy.debug == true



##
##
##



- delegate_to: localhost
  block:



      ##
      ##    NOTE: All tasks here are blocked and delegated to excute
      ##          on the deployhost/localhost when deploy_node = true
      ##



      ##
      ##    Cleanup and create a fresh temp workspace
      ##



      - name: "ovirt-deploy : DEBUG temp workspace details"
        debug: 
          msg:
          - "temp workspace = {{ xtoph_deploy.deployhost.tmp_dir }}"
        when: xtoph_deploy.debug == true

      - name: "ovirt-deploy : delete old temp workspace"
        shell:
          cmd: |
            if [[ -d "{{ xtoph_deploy.deployhost.tmp_dir }}" ]] ; then rm -rf {{ xtoph_deploy.deployhost.tmp_dir }} ; fi
  
      - name: "ovirt-deploy : create new temp workspace"
        file:
          path="{{ xtoph_deploy.deployhost.tmp_dir }}/{{ item }}"
          mode="0755"
          state=directory
        loop:
          - iso
          - artifacts 



      - block:
  
            ##
            ##    All tasks in this block are related to
            ##    kickstart repo and kickstart url setup
            ##
            ##    * NOTE * to avoid concurrency problems when
            ##             when detecting and mounting the iso
            ##             mount, we set 'throttle = 1'
            ##
  
  
  
            - name: "ovirt-deploy : DEBUG repo loopback details"
              debug: 
                msg:
                 - "repo mnt = {{ xtoph_deploy.deployhost.repos.dir }}/{{ xtoph_deploy.kickstart_profile.mnt }}"
                 - "repo src = {{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.repo_iso }}"
              when: xtoph_deploy.debug == true
  
            - name: "ovirt-deploy : stat repo mount point"
              throttle: 1
              stat: path="{{ xtoph_deploy.deployhost.repos.dir }}/{{ xtoph_deploy.kickstart_profile.mnt }}"
              register: test_repo_mount
              when: xtoph_deploy.kickstart_profile is defined and 
                    xtoph_deploy.kickstart_profile.repo_iso != ""
  
            - name: "ovirt-deploy : create repo mount point"
              throttle: 1
              file: 
                path:  "{{ xtoph_deploy.deployhost.repos.dir }}/{{ xtoph_deploy.kickstart_profile.mnt }}" 
                mode:  "0755"
                state: directory
              when: test_repo_mount.stat.exists == false
  
            - name: "ovirt-deploy : mount iso"
              throttle: 1
              vars:
              mount:
                path:   "{{ xtoph_deploy.deployhost.repos.dir }}/{{ xtoph_deploy.kickstart_profile.mnt }}"
                src:    "{{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.repo_iso }}"
                opts:   "loop,ro"
                state:  "mounted"
                fstype: "iso9660"
              when: xtoph_deploy.kickstart_profile.repo_iso != ""
  
  
  
            ##
            ##
            ##    Create ks.cfg in http directory.  For ovirt
            ##    deployments we currently cook the ks.cfg
            ##    directly into the ISO.
            ##
            ##    NOTE: using run-once and specifying kernel,
            ##          initrd and kernel args only works with
            ##          local and iso storage domains (BUG?).
            ##
            ##          ovirt api does not support uploads to
            ##          the iso-domain
            ##
            ##          I am not interested in managing file
            ##          distribution to all rhv-h local domains
            ##
            ##          THIS IS WHY THE CUSTOM ISO METHOD IS
            ##          THE CURRENT SOLUTION
            ##
            ##          I have enabled a smaller solution using
            ##          the rhel "boot" ISO (700Mb vs. 8G) with
            ##          a simple kickstart_profile definition which
            ##          then performs the install from the
            ##          http hosted repo.
            ##
  
  
  
            ##
            ##    Create the custom ISO for the OS installation
            ##
            ##    * NOTE * to avoid concurrency problems with
            ##             disk space and i/o bandwidth, we
            ##             use serial at the import_task level
            ##             DO NOT use "throttle" here as a stop gap
            ##
    
    
            - name: "ovirt-deploy : test iso availability"
              stat:
                path: "{{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.boot_iso }}"
              register: iso_result
  
            - fail:
                msg: "Specified ISO does not exist: {{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.boot_iso }}"
              when: not iso_result.stat.exists
    
            - name: "ovirt-deploy : clone ISO source to temp workspace"
              vars:
                t_isofile: "{{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.boot_iso }}"
                t_destdir: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso"
              shell:
                cmd: |
                  xorriso -osirrox on -indev "{{ t_isofile }}" -extract / "{{ t_destdir }}"
    
            - name: "ovirt-deploy : preserve the ISO volume id"
              vars:
                t_isofile: "{{ xtoph_deploy.deployhost.iso.dir }}/{{ xtoph_deploy.kickstart_profile.boot_iso }}"
              shell:
                cmd: |
                  isoinfo -d -i {{ t_isofile }} | grep 'Volume id:' | sed -e 's/Volume id: //g'
              register: isoinfo_volume_id

  
  
            ##
            ##    Create the kickstart config
            ##
            ##    NOTE: put 1 copy in kcisktart url directory
            ##          and 1 on the ISO
            ##
  
  
  
            - name: "ovirt-deploy : create kickstart http dir '{{ xtoph_deploy.deployhost.kickstart.dir }}'"
              file: path="{{ xtoph_deploy.deployhost.kickstart.dir }}" mode="0755" state=directory
        
        
            - name: "ovirt-deploy : deploy kickstart config iso temp workspace and http dir"
              vars:
                p_ssh_key:    "{{ lookup('file','/root/.ssh/id_rsa.pub') }}"
                p_diskDevice: "{{ xtoph_deploy.hardware_profile.disk.dev }}"
              template:
                src:   "{{ xtoph_deploy.kickstart_profile.template }}"
                dest:  "{{ item }}"
                owner: root
                group: root
                mode: 0444
              loop:
                - "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/ks.cfg"
                - "{{ xtoph_deploy.deployhost.kickstart.dir }}/{{ g_clusterName }}-{{ inventory_hostname }}.cfg"
  
  
  
            ##
            ##    Adjust the isolinux.cfg
            ##
    
    
    
            - name: "ovirt-deploy : isolinux.cfg: change default timeout to 3 seconds"
              replace:
                path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg"
                regexp: '^timeout(\s+.*)?$'
                replace: 'timeout 30'
        
            - name: "ovirt-deploy : remove default menu option from isolinux.cfg"
              lineinfile:
                dest: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg"
                regexp: "^.*menu default.*$"
                state:  absent
        
            - name: "ovirt-deploy : set new default menu option in isolinux.cfg"
              lineinfile:
                dest: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg"
                insertafter: "^.*label linux.*$"
                line: "  menu default"
                state: present



            ##
            ##    Adjust the grub.cfg (UEFI)
            ##
      
      
      
            - name: "ovirt-deploy : grub.cfg : change default menu option"
              replace:
                path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/EFI/BOOT/grub.cfg"
                regexp: '^set timeout=.*$'
                replace: 'set timeout=30'
      
            - name: "ovirt-deploy : grub.cfg : change default timeout to 3 seconds"
              replace:
                path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/EFI/BOOT/grub.cfg"
                regexp: '^set default=.*$'
                replace: 'set default="0"'

  

            ##    
            ##    NOTE:  
            ##    
            ##      Reference: 'man -7 dracut.cmdline', format for static ip= is as follows:
            ##   
            ##        ip=<client-IP>:[<peer>]:<gateway-IP>:<netmask>:<client_hostname>:<interface>:{none|off|dhcp|on|any|dhcp6|auto6|ibft}[:[<dns1>][:<dns2>]]   
            ##   
            ##      Reference: http://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames
            ##
            ##        interface names 'enoX = onboard', 'ensX = pci-express', 'enp2s0 = physical location', 'enxYYYYYYYYYYYY = macaddress'
            ##
            ##      More discussions:
            ##      
            ##        https://fedoraproject.org/wiki/Dracut/Options#Network      
            ##        https://bugzilla.redhat.com/show_bug.cgi?id=836039
            ##


            - block:
      
                ##
                ##    All tasks in this block are related to
                ##    kernel parameter adjustments for
                ##    the installation media
                ##
                ##    * NOTE * vars are defined once for the
                ##             for the whole block at the end
                ##             of the block
                ##
      
                - name: "ovirt-deploy : isolinux.cfg : kernel args for BIOS iso (cdrom install)"
                  replace:
                    path:   "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg"
                    regexp: '(\s+)append(\s+.*)?$'
                    replace: >
                        \1append\2
                        inst.text
                        inst.ks=cdrom:/ks.cfg
                        ksdevice={{ t_net_dev }}
                        ip={{ t_net_ip }}::{{ t_net_gw }}:{{ t_net_nm }}::{{ t_net_dev }}:none
                        nameserver={{ t_net_dns }}
                  when: xtoph_deploy.kickstart_profile.method == "cdrom"
      
                - name: "ovirt-deploy : grub.cfg : kernel args for UEFI iso (cdrom install)"
                  replace:
                    path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/EFI/BOOT/grub.cfg"
                    regexp: '(\s+)linuxefi(\s+.*)?$'
                    replace: >
                        \1linuxefi\2
                        inst.text
                        inst.ks=cdrom:/ks.cfg
                        ksdevice={{ t_net_dev }}
                        ip={{ t_net_ip }}::{{ t_net_gw }}:{{ t_net_nm }}::{{ t_net_dev }}:none
                        nameserver={{ t_net_dns }}
                  when: xtoph_deploy.kickstart_profile.method == "cdrom"

                - name: "ovirt-deploy : isolinux.cfg : kernel args for BIOS boot-iso (network install)"
                  replace:
                    path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg"
                    regexp: '(\s+)append(\s+.*)?$'
                    replace: >
                        \1append\2
                        inst.text
                        inst.ks={{ t_ks_url }}
                        inst.repo={{ t_ks_repo }}
                        ksdevice={{ t_net_dev }}
                        ip={{ t_net_ip }}::{{ t_net_gw }}:{{ t_net_nm }}::{{ t_net_dev }}:none
                        nameserver={{ t_net_dns }}
                  when: xtoph_deploy.kickstart_profile.method == "network"
      
                - name: "ovirt-deploy : grub.cfg : kernel args for UEFI boot-iso (network install)"
                  replace:
                    path: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/EFI/BOOT/grub.cfg"
                    regexp: '(\s+)linuxefi(\s+.*)?$'
                    replace: >
                        \1linuxefi\2
                        inst.text
                        inst.ks={{ t_ks_url }}
                        inst.repo={{ t_ks_repo }}
                        ksdevice={{ t_net_dev }}
                        ip={{ t_net_ip }}::{{ t_net_gw }}:{{ t_net_nm }}::{{ t_net_dev }}:none
                        nameserver={{ t_net_dns }}
                  when: xtoph_deploy.kickstart_profile.method == "network"
      
      
      
              vars:
                t_net_dev:  "{{ xtoph_deploy.hardware_profile.network.dev   }}"
                t_net_ip:   "{{ xtoph_deploy.ovirt.network.net0.ip      }}"
                t_net_nm:   "{{ xtoph_deploy.ovirt.network.net0.netmask }}"
                t_net_gw:   "{{ xtoph_deploy.ovirt.network.net0.gateway }}"
                t_net_dns:  "{{ xtoph_deploy.deployhost.ip if xtoph_deploy.deployhost.dnsmasq_asprimary == true else xtoph_deploy.ovirt.network.net0.nameserver }}"
                t_ks_repo:  "{{ xtoph_deploy.deployhost.repos.url }}/{{ xtoph_deploy.kickstart_profile.mnt }}"
                t_ks_url:   "{{ xtoph_deploy.deployhost.kickstart.url }}/{{ g_clusterName }}-{{ inventory_hostname }}.cfg"
      
              ## End-Of-Block



            ##
            ##    Preserve some files in the temp workspace
            ##    artifacts directory for easy debugging
            ##
  
  
      
            - name: "ovirt-deploy : copy files to temp workspace artifacts directory for preservation"
              copy:
                dest: "{{ xtoph_deploy.deployhost.tmp_dir }}/artifacts"
                src:  "{{ item }}"
              loop:
                - "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/isolinux/isolinux.cfg" 
                - "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/ks.cfg" 
                - "{{ xtoph_deploy.deployhost.tmp_dir }}/iso/EFI/BOOT/grub.cfg"

             
            - name: "ovirt-deploy : save state of xtoph_deploy dictionary to artifacts directory"
              copy:
                dest:     "{{ xtoph_deploy.deployhost.tmp_dir }}/artifacts/xtoph_deploy.yml"
                content:  "{{ xtoph_deploy | to_nice_yaml }}"
           
      
      
            ##
            ##    Generate the custom ISO image
            ##
 

 
            - name: "ovirt-deploy : create script to generate iso"
              vars:
                t_iso_label:  "{{ isoinfo_volume_id.stdout }}"
                t_iso_source: "{{ xtoph_deploy.deployhost.tmp_dir }}/iso"
                t_iso_output: "{{ xtoph_deploy.deployhost.tmp_dir }}/{{ xtoph_deploy.ovirt.vm.name }}.iso"
              template:
                src: "mkiso.j2"
                dest: "{{ xtoph_deploy.deployhost.tmp_dir }}/artifacts/mkiso.sh"
                owner: root
                group: root
                mode: 0755
    
            - name: "ovirt-deploy : execute mkiso.sh script"
              shell:
                cmd: |
                  {{ xtoph_deploy.deployhost.tmp_dir }}/artifacts/mkiso.sh
  
  
  
            ##
            ##    Transfer the ISO image to ovirt storage domain
            ##
            ##    NOTE: to avoid concurrency problems with
            ##          disk space and i/o bandwidth, we
            ##          set 'throttle = 1'
            ##
      
      
  
            - name: "ovirt-deploy : upload iso image"
              throttle: 1
              ovirt_disk:
                auth: "{{ ovirt_auth }}"
                name: "{{ xtoph_deploy.ovirt.vm.name }}.iso"
                description: "{{ xtoph_deploy.ovirt.vm.name }}.iso"
                upload_image_path: "{{ xtoph_deploy.deployhost.tmp_dir }}/{{ xtoph_deploy.ovirt.vm.name }}.iso"
                bootable: true
                content_type: iso
                format: raw
                storage_domain: "{{ xtoph_deploy.ovirt.storage.domain }}"
      

      
            - name: "ovirt-deploy : clean-up temporary work-space"
              shell:
                cmd: |
                  if [[ -d "{{ xtoph_deploy.deployhost.tmp_dir }}/iso" ]] ; then
                    rm -rf "{{ xtoph_deploy.deployhost.tmp_dir }}/iso"
                  fi
    
                  if [[ -e "{{ xtoph_deploy.deployhost.tmp_dir }}/{{ xtoph_deploy.ovirt.vm.name }}.iso" ]] ; then
                    rm -f "{{ xtoph_deploy.deployhost.tmp_dir }}/{{ xtoph_deploy.ovirt.vm.name }}.iso"
                  fi
              when: xtoph_deploy.cleanup == true

        when: xtoph_deploy.kickstart_profile is defined and
              xtoph_deploy.kickstart_profile.method != "pxe"



      ##
      ##    Create virtual machine
      ##
      ##    NOTE:  the kickstart_profile can override the
      ##           hardware_profile default os_type.  This
      ##           provides easy customization of kvm
      ##           optimizations per OS
      ##

  
  
      - name: "ovirt-deploy : create vm with cpu, mem and nics"
        ovirt_vm:
          auth:      "{{ ovirt_auth }}"
          name:      "{{ xtoph_deploy.ovirt.vm.name }}"
          cluster:   "{{ xtoph_deploy.ovirt.cluster_name }}"
          memory:    "{{ xtoph_deploy.resource_profile.memsize }} MiB"
          cpu_cores: "{{ xtoph_deploy.resource_profile.vcpus }}"
          nics:
            - name: "nic1"
              interface: "{{ xtoph_deploy.hardware_profile.network.model }}"
              profile_name: "{{ xtoph_deploy.ovirt.network.net0.ovirt_network }}"
              mac_address: "{{ h_pubMAC }}"
          graphical_console:
             protocol:
               - spice
          operating_system: "{{ xtoph_deploy.kickstart_profile.kvm_os_type | default(xtoph_deploy.hardware_profile.default_os_type) }}"
          high_availability: false
          type: server
          state: stopped
          wait: yes



      ##
      ##    Add boot disk to virtual machine
      ##



      - name: "ovirt-deploy : modify vm with boot-disk"
        ovirt_disk:
          auth:              "{{ ovirt_auth }}"
          name:              "{{ xtoph_deploy.ovirt.vm.name }}_root"
          vm_name:           "{{ xtoph_deploy.ovirt.vm.name }}"
          storage_domain:    "{{ xtoph_deploy.ovirt.storage.domain }}"
          interface:         "{{ xtoph_deploy.hardware_profile.disk.bus }}"
          sparse:            "{{ xtoph_deploy.hardware_profile.disk.sparse }}"
          size:              "{{ xtoph_deploy.resource_profile.storage.root.size }} GiB"
          bootable:          yes
          format:            cow
          wipe_after_delete: yes
          wait:              yes

      - name: "ovirt-deploy : modify vm with extra disks"
        ovirt_disk:
          auth:              "{{ ovirt_auth }}"
          name:              "{{ xtoph_deploy.ovirt.vm.name }}_{{ t_diskname }}"
          vm_name:           "{{ xtoph_deploy.ovirt.vm.name }}"
          storage_domain:    "{{ xtoph_deploy.ovirt.storage.domain }}"
          interface:         "{{ xtoph_deploy.hardware_profile.disk.bus }}"
          sparse:            "{{ xtoph_deploy.hardware_profile.disk.sparse }}"
          size:              "{{ xtoph_deploy['resource_profile']['storage']['extra'][t_diskname].size }} GiB"
          bootable:          no
          format:            cow
          wipe_after_delete: yes
          wait:              yes
        loop: "{{ xtoph_deploy.resource_profile.storage.extra | flatten(1) }}"
        loop_control:
          loop_var: t_diskname
        when: xtoph_deploy.resource_profile.storage.extra is defined



      ##
      ##
      ##    Configure boot device based on ISO availability
      ##
      ##



      - name: "ovirt-deploy : vm attach ISO and change boot device to cdrom"
        ovirt_vm:
          auth:         "{{ ovirt_auth }}"
          name:         "{{ xtoph_deploy.ovirt.vm.name }}"
          cluster:      "{{ xtoph_deploy.ovirt.cluster_name }}"
          cd_iso:       "{{ xtoph_deploy.ovirt.vm.name }}.iso"
          boot_devices:
            - cdrom
            - hd
        when:
          - xtoph_deploy.kickstart_profile is defined and
            xtoph_deploy.kickstart_profile.method != "pxe"

      - name: "ovirt-deploy : vm change boot device to network"
        ovirt_vm:
          auth:         "{{ ovirt_auth }}"
          name:         "{{ xtoph_deploy.ovirt.vm.name }}"
          cluster:      "{{ xtoph_deploy.ovirt.cluster_name }}"
          boot_devices:
            - hd
            - network
        when:
          - xtoph_deploy.kickstart_profile is defined and
            xtoph_deploy.kickstart_profile.method == "pxe"

      - name: "ovirt-deploy : vm change state to RUNNING (START INSTALL)"
        ovirt_vm:
          auth: "{{ ovirt_auth }}"
          name: "{{ xtoph_deploy.ovirt.vm.name }}"
          cluster: "{{ xtoph_deploy.ovirt.cluster_name }}"
          state: running
          wait: no

    ##
    ## End - block:
    ##

  when: deploy_node == true



- delegate_to: localhost
  block:

    ##
    ##    Log out of the oVIRT API service
    ##
    
    - name: Logout from oVirt
      throttle: 1
      ovirt_auth:
        state: absent
        ovirt_auth: "{{ ovirt_auth }}"

